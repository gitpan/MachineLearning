<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>MachineLearning::NeuralNetwork</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
  </head>
  <body>
    <div class="pod">
      <!-- INDEX START -->
      <h3>Index</h3>
      <ul>
        <li><a href="#NAME">NAME</a></li>
        <li><a href="#SYNOPSIS">SYNOPSIS</a></li>
        <li><a href="#DESCRIPTION">DESCRIPTION</a></li>
        <li><a href="#PREREQUISITES">PREREQUISITES</a></li>
        <li><a href="#METHODS">METHODS</a></li>
        <li><a href="#NEURAL_NETWORK_DATA">NEURAL NETWORK DATA</a></li>
        <li><a href="#NEURAL_NETWORK_ARCHITECTURE">NEURAL NETWORK
          ARCHITECTURE</a></li>
        <li><a href="#AUTHOR">AUTHOR</a></li>
        <li><a href="#COPYRIGHT_AND_LICENSE">COPYRIGHT AND LICENSE</a></li>
      </ul>
      <hr/>
      <!-- INDEX END -->
      <h1 id="NAME">NAME</h1>
      <div id="NAME_CONTENT">
        <p>MachineLearning::NeuralNetwork &#8211; create, train, test,
          resize, store, and run a neural network</p>
      </div>
      <h1 id="SYNOPSIS">SYNOPSIS</h1>
      <div id="SYNOPSIS_CONTENT">
        <pre>  use MachineLearning::NeuralNetwork;
  my $nn = MachineLearning::NeuralNetwork-&gt;new({
    &quot;Name&quot; =&gt; &quot;Sample Network&quot;,
    &quot;Description&quot; =&gt; &quot;Sample network&quot;,
    &quot;HiddenLayerSize&quot; =&gt; 5,
    &quot;InputFieldNames&quot; =&gt; [&quot;Input1&quot;, &quot;Input2&quot;],
    &quot;OutputFieldNames&quot; =&gt; [&quot;Output&quot;]});
  my $nn = MachineLearning::NeuralNetwork-&gt;open(
    &quot;~/neural_networks/sample.nn&quot;);
  my $success = $nn-&gt;get_success();
  my $message = $nn-&gt;get_message();
  my $network_name = $nn-&gt;get_name();
  my $network_description = $nn-&gt;get_description();
  my $ran_ok = $nn-&gt;run($data_file_path);
  my $trained_ok = $nn-&gt;train({
    &quot;TrainingDataFilePath&quot; =&gt; $training_data_file_path,
    &quot;CyclesPerTemperature&quot; =&gt; $cycles_per_temperature,
    &quot;MinimumOnesPercentage&quot; =&gt; $minimum_ones_percentage});
  my $test_results = $nn-&gt;test($validation_data_file_path);
  my $new_hidden_layer_size = $nn-&gt;grow({
    &quot;TrainingDataFilePath&quot; =&gt; $training_data_file_path,
    &quot;ValidationDataFilePath&quot; =&gt; $validation_data_file_path,
    &quot;CyclesPerTemperature&quot; =&gt; $cycles_per_temperature,
    &quot;MinimumOnesPercentage&quot; =&gt; $minimum_ones_percentage});
  my $new_hidden_layer_size = $nn-&gt;prune({
    &quot;TrainingDataFilePath&quot; =&gt; $training_data_file_path,
    &quot;ValidationDataFilePath&quot; =&gt; $validation_data_file_path,
    &quot;CyclesPerTemperature&quot; =&gt; $cycles_per_temperature,
    &quot;MinimumOnesPercentage&quot; =&gt; $minimum_ones_percentage});
  my $saved_ok = $nn-&gt;save(&quot;~/neural_networks/perfected_network.nn&quot;);
</pre>
      </div>
      <h1 id="DESCRIPTION">DESCRIPTION</h1>
      <div id="DESCRIPTION_CONTENT">
        <p>This module defines a package for creating a
          MachineLearning::NeuralNetwork object.</p>
        <p>This module uses the MachineLearning::SimulatedAnnealing module
          to optimize the network&#39;s weights and thresholds during
          training.</p>
        <p>A neural network as implemented by the
          MachineLearning::NeuralNetwork module favors quality over
          quantity. That is, it is optimized to find the highest quality
          predictions for a single result value without particular regard to
          how many data records (or instances) get screened out in the
          process. This is highly useful for many applications. For example,
          out of many potential financial investments, you might want to
          identify a small group that have unusually good prospects for
          success.</p>
        <p>The result values supported by the MachineLearning::NeuralNetwork
          module are <code>1</code> and <code>0</code>, and the accuracy of
          the results is important only for the <code>1</code> values. To
          ensure that the neural network&#39;s output layer generates a
          satisfactory minimum quantity of ones, the methods for training,
          growing, and pruning the neural network take an optional
          MinimumOnesPercentage argument.</p>
      </div>
      <h1 id="PREREQUISITES">PREREQUISITES</h1>
      <div id="PREREQUISITES_CONTENT">
        <p>To use this module, you must have both the MachineLearning module
          and the MachineLearning::SimulatedAnnealing module installed.</p>
      </div>
      <h1 id="METHODS">METHODS</h1>
      <div id="METHODS_CONTENT">
        <dl>
          <dt>MachineLearning::NeuralNetwork-&gt;new($args);</dt>
          <dd>
            <p>This is the constructor.</p>
            <p>In addition to the class-name argument, which is passed
              automatically when you use the
              <code>MachineLearning::NeuralNetwork-&gt;new()</code> syntax,
              the constructor takes a reference to a hash containing the
              following keys:</p>
            <pre>  Name
  Description
  HiddenLayerSize
  InputFieldNames
  OutputFieldNames
</pre>
            <p>The Name and Description must be non-empty strings. The
              HiddenLayerSize must be a positive integer specifying the
              number of neurons in the neural network&#39;s hidden layer.
              The value associated with the InputFieldNames key must be a
              reference to an array of input field names. The value
              associated with the OutputFieldNames key must be a reference
              to an array containing exactly one output field name.</p>
            <p>All field names (for input and output fields combined) must
              be unique. Field names must not contain commas or line-break
              characters. There must be at least two input field names and
              exactly one output field name.</p>
            <p>The constructor returns a reference to a
              MachineLearning::NeuralNetwork object, which is implemented
              internally as a hash. All functionality is exposed through
              methods.</p>
            <p>If the constructor receives a valid hash reference providing
              all required information, the <code>get_success()</code>
              instance method returns true (<code>1</code>) and the
              <code>get_message()</code> instance method returns an empty
              string; otherwise, <code>get_success()</code> returns false
              (<code>0</code>) and <code>get_message()</code> returns a
              string containing an error message.</p>
          </dd>
          <dt>$nn-&gt;get_success();</dt>
          <dd>
            <p>This returns true (<code>1</code>) if the neural network
              object was initialized successfully; otherwise, it returns
              false (<code>0</code>).</p>
          </dd>
          <dt>$nn-&gt;get_message();</dt>
          <dd>
            <p>When <code>get_success()</code> returns true
              (<code>1</code>), this returns an empty string. When
              <code>get_success()</code> returns false (<code>0</code>),
              <code>get_message()</code> returns an error message.</p>
          </dd>
          <dt>$nn-&gt;get_name();</dt>
          <dd>
            <p>Returns the name of the neural network, or an empty string if
              the neural network was never successfully initialized.</p>
          </dd>
          <dt>$nn-&gt;get_description();</dt>
          <dd>
            <p>Returns the description of the neural network, or an empty
              string if the neural network was never successfully
              initialized.</p>
          </dd>
          <dt>$nn-&gt;run($data_file_path);</dt>
          <dd>
            <p>This method runs the neural network on the specified data.</p>
            <p>The specified data file must be in CSV format with a header
              row. The header row must contain the names of the input
              neurons in the correct order followed by the name of the
              output neuron. <strong>NOTE:</strong> There can be more than
              one output field; however, the neural network uses
              <em>and&nbsp;preserves</em> only the one for which the
              column&nbsp;heading matches the output-field name associated
              with the neural network.</p>
            <p>Each record in the data must contain the correct number of
              input values as well as a blank or replaceable output value in
              the appropriate output field. <strong>IMPORTANT:</strong>
              The method removes all other output fields from the file.</p>
            <p>The method adds the neural&nbsp;network&#8211;generated
              output value to each record, overwriting the output value that
              is already there, if any. <strong>NOTE:</strong> Input and
              output values must not contain commas or line-break
              characters.</p>
            <p>If everything goes OK, the method returns true
              (<code>1</code>); otherwise, the method returns false
              (<code>0</code>). If the neural network was in a valid state
              previously but something went wrong during execution of the
              <code>run()</code> method, the method sets the
              <code>_success</code> field (returned by the
              <code>get_success()</code> method) to false (<code>0</code>)
              and places an error message in the <code>_message</code> field
              (returned by the <code>get_message()</code> method).</p>
          </dd>
          <dt>$nn-&gt;train($args);</dt>
          <dd>
            <p><code>$args</code> is a reference to a hash containing the
              following keys:</p>
            <pre>  TrainingDataFilePath
  CyclesPerTemperature
  MinimumOnesPercentage
</pre>
            <p>This method trains the neural network using the specified
              data and the specified number of cycles per temperature. The
              value specifying the minimum percentage of ones required for
              the output node to avoid an automatic cost assessment of
              <code>100</code> is optional and, if missing or invalid, is
              assumed to be <code>0</code>. Even if the minimum ones
              percentage is <code>0</code>, however, there must always be at
              least one occurrence of a <code>1</code> result for the output
              neuron to avoid an automatic cost assessment of
              <code>100</code>.</p>
            <p>The training data must be in CSV format with a header row.
              The header row must contain the names of the input neurons in
              the correct order followed by the name of the output neuron.
              <strong>NOTE:</strong> There can be more than one output
              field; however, the neural network uses only the one for which
              the column heading matches the output field name associated
              with the neural network.</p>
            <p>Each record in the data must contain the correct number of
              input values as well as an output value in the appropriate
              output field. The output value supplied with the training data
              is typically the expected, ideal, or real-life result for the
              supplied input values. <strong>NOTE:</strong> Input and output
              values must not contain commas or line-break characters.</p>
            <p>CyclesPerTemperature is a positive integer (for example,
              <code>1_000</code>) specifying the number of randomization
              cycles performed at each temperature level during the
              simulated annealing process. (For more information, see the
              MachineLearning::SimulatedAnnealing module).</p>
            <p>During training, the network minimizes <i>cost</i> using
              simulated annealing to optimize the weights and thresholds.
              <i>Cost</i> is a number that represents how much error results
              when a particular set of weights and thresholds is applied to
              the training data. The cost is the percentage of the time that
              the <code>1</code> values in the output generated by the
              network do not match the corresponding values provided by the
              training data.</p>
            <p>If specified, the MinimumOnesPercentage value must be a
              positive number less than 100 that represents a percentage.
              The cost calculated for the output neuron&#39;s values over a
              data set will be set to <code>100</code> automatically if the
              percentage of ones is less than the specified minimum (or if
              there are no ones at all).</p>
            <p>If everything goes OK, the method returns true
              (<code>1</code>); otherwise, the method returns false
              (<code>0</code>). If the neural network was in a valid state
              previously but something went wrong during execution of the
              <code>train()</code> method, the method sets the
              <code>_success</code> field (returned by the
              <code>get_success()</code> method) to false (<code>0</code>)
              and places an error message in the <code>_message</code> field
              (returned by the <code>get_message()</code> method).</p>
          </dd>
          <dt>$nn-&gt;test($validation_data_file_path);</dt>
          <dd>
            <p>This method tests the network using the supplied validation
              data, which must be in the same format as the training data.</p>
            <p>The method returns a string containing the test results in
              the form of a formatted report, which gives the <i>cost</i>
              for the output neuron.</p>
            <p><i>Cost</i> is a number that represents how much error
              results when the neural network is applied to the test data.
              The cost is the percentage of the time that the <code>1</code>
              values in the output generated by the network do not match the
              corresponding values provided by the test data.</p>
            <p>During training, the network minimizes cost using simulated
              annealing to optimize the weights and thresholds. During
              testing, however, there are no adjustments to the weights and
              thresholds; the results are simply calculated and reported.</p>
            <p><strong>TIP:</strong> Testing reveals how well the network
              generalizes to out-of-sample data. Therefore, make sure that
              the validation data does not overlap with the training data.
              To compare the test results with the results of applying the
              network to the data on which it was trained, you can run a
              test using the training data. The cost is typically higher for
              the test data, so the important question is whether that cost
              is sufficiently low for the network to be useful.</p>
            <p>If something goes wrong during execution of the method, the
              method returns an empty string and, if the
              <code>_success</code> field (returned by the
              <code>get_success()</code> method) is currently set to true
              (<code>1</code>), sets that field to false (<code>0</code>)
              and places an error message in the <code>_message</code> field
              (returned by the <code>get_message()</code> method).</p>
          </dd>
          <dt>$nn-&gt;grow($args);</dt>
          <dd>
            <p><code>$args</code> is a reference to a hash containing the
              following keys:</p>
            <pre>  TrainingDataFilePath
  ValidationDataFilePath
  CyclesPerTemperature
  MinimumOnesPercentage
</pre>
            <p>The MinimumOnesPercentage key is optional.</p>
            <p>This method grows the neural network by performing training
              and testing with a progressively increasing number of hidden
              neurons. The size of the hidden layer starts at five and then
              progresses upward through the Fibonacci series to 144 (that
              is, the sizes used are 5, 8, 13, 21, 34, 55, 89, and 144).
              Once the neural network has been trained and tested with a
              hidden layer size of 144, the method chooses the size with the
              best result (the lowest cost) based on post-training
              validation, retrains the network with that number of hidden
              neurons, and then returns that number. <strong>NOTE:</strong>
              In the case of a tie, the method favors the smaller number of
              hidden neurons.</p>
            <p>If something goes wrong during execution of the method, the
              method returns <code>0</code> and, if the
              <code>_success</code> field (returned by the
              <code>get_success()</code> method) is currently set to true
              (<code>1</code>), sets that field to false (<code>0</code>)
              and places an error message in the <code>_message</code> field
              (returned by the <code>get_message()</code> method).</p>
          </dd>
          <dt>$nn-&gt;prune($args);</dt>
          <dd>
            <p><code>$args</code> is a reference to a hash containing the
              following keys:</p>
            <pre>  TrainingDataFilePath
  ValidationDataFilePath
  CyclesPerTemperature
  MinimumOnesPercentage
</pre>
            <p>The MinimumOnesPercentage key is optional.</p>
            <p>This method prunes the neural network by performing training
              followed by testing with a progressively decreasing number of
              hidden neurons. The size of the hidden layer decreases by one
              for each cycle of training and testing. Once all sizes have
              been tried from the initial size down to the closest lower
              number that is in the Fibonacci series, the method chooses the
              size with the best result (the lowest cost), retrains the
              network with that number of hidden neurons, and returns that
              number. <strong>NOTE:</strong> In the case of a tie, the
              method favors the smaller number of hidden neurons.</p>
            <p>If something goes wrong during execution of the method, the
              method returns <code>0</code> and, if the
              <code>_success</code> field (returned by the
              <code>get_success()</code> method) is currently set to true
              (<code>1</code>), sets that field to false (<code>0</code>)
              and places an error message in the <code>_message</code> field
              (returned by the <code>get_message()</code> method).</p>
          </dd>
          <dt>$nn-&gt;save($file_path);</dt>
          <dd>
            <p>This method saves (<i>serializes</i>) the neural network
              object to a file. A neural network must be already trained
              before you can save it.</p>
            <p>If the serialization and file-writing operations succeed,
              this method returns true (<code>1</code>); otherwise, the
              method sets the <code>_success</code> field to false
              (<code>0</code>), places an error message in the
              <code>_message</code> field, and returns false
              (<code>0</code>).</p>
          </dd>
          <dt>MachineLearning::NeuralNetwork-&gt;open($file_path);</dt>
          <dd>
            <p>This method returns a new MachineLearning::NeuralNetwork
              object created by restoring such an object from the specified
              file. If the file-reading and deserialization operations
              succeed, the resulting object&#39;s <code>get_success()</code>
              method returns true (<code>1</code>) and the
              <code>get_message()</code> method returns an empty string.
              Otherwise, the <code>open()</code> method creates and returns
              a new object that has a false value in the
              <code>_success</code> field and an error message in the
              <code>_message</code> field.</p>
          </dd>
        </dl>
      </div>
      <h1 id="NEURAL_NETWORK_DATA">NEURAL NETWORK DATA</h1>
      <div id="NEURAL_NETWORK_DATA_CONTENT">
        <p>All input values must be decimal numbers in the range
          <code>-1</code> to <code>1</code>, inclusive.</p>
        <p>Internally, the neural network uses weight values in the range
          <code>-1</code> to <code>1</code> (inclusive) and thresholds in
          the range <code>0.00000001</code> to <i>n</i>, where <i>n</i> is
          the number of neurons in the preceding layer. Both the hidden and
          output layers have thresholds, and the output value is determined
          by whether the threshold for the output node is reached
          (<code>1</code> if yes, <code>0</code> if no).</p>
        <p>All output values provided by training data or validation data
          must be either <code>0</code> or <code>1</code>.</p>
      </div>
      <h1 id="NEURAL_NETWORK_ARCHITECTURE">NEURAL NETWORK ARCHITECTURE</h1>
      <div id="NEURAL_NETWORK_ARCHITECTURE_CONTENT">
        <p>This module uses a feed-forward neural network architecture with
          one hidden layer. The number of hidden nodes is variable, and the
          recommended approach is to try various numbers in ascending order
          (for example, by using the <code>grow()</code> method). Then,
          starting with the number that produced the best results based on
          post-training validation, prune the neural network using the
          <code>prune()</code> method.</p>
        <p><strong>TIP:</strong> You can grow and then prune a neural
          network several times using different data sets in order to gain
          more insight into the optimal size for the hidden layer. You can
          also switch the training and validation sets to get twice as many
          train-and-test cycles from your data. When using these approaches,
          consider reserving sufficient data for a final test; data that is
          not part of any of the data sets that you are using for training
          and validation during the development phase of the neural network.
          If the final test is not satisfactory, you might have to
          reconsider the types of inputs that you are using for the neural
          network, gather sufficient additional data for a new final test,
          and then develop the neural network again using a different input
          framework.</p>
      </div>
      <h1 id="AUTHOR">AUTHOR</h1>
      <div id="AUTHOR_CONTENT">
        <p>Benjamin Fitch, &lt;blernflerkl@yahoo.com&gt;</p>
      </div>
      <h1 id="COPYRIGHT_AND_LICENSE">COPYRIGHT AND LICENSE</h1>
      <div id="COPYRIGHT_AND_LICENSE_CONTENT">
        <p>Copyright 2009 by Benjamin Fitch</p>
        <p>This library is free software; you can redistribute it and/or
          modify it under the same terms as Perl itself.</p>
      </div>
    </div>
  </body>
</html>
